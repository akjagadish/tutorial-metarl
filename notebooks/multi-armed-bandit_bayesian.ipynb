{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from compositional_metarl.task import MultiArmedBandit\n",
    "from compositional_metarl.model import QDNDLSTM as Agent\n",
    "from compositional_metarl.utils import compute_stats, to_sqnp\n",
    "from compositional_metarl.model.DND import compute_similarities\n",
    "from compositional_metarl.model.utils import get_reward, compute_returns, compute_a2c_loss, get_reward_mab, run_agent_inference\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import torch.nn.functional as F\n",
    "from compositional_metarl.trainers import Trainer, evaluate\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "sns.set(style='white', context='talk', palette='colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 0 \n",
    "torch.manual_seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.cuda.manual_seed(seed_val)\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' task'''\n",
    "\n",
    "start_arm = 0\n",
    "end_arm = 7\n",
    "ctx_dim = 2\n",
    "n_arms = (end_arm - start_arm) + 1\n",
    "n_rounds = 20\n",
    "n_trials = 10\n",
    "normalize_rewards = True\n",
    "CUES =  {'linear': torch.tensor([1.0, 0.0]), 'periodic': torch.tensor([0.0, 1.0])} #, 'linperiodic': torch.tensor([1.0, 1.0])} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' model'''\n",
    "\n",
    "inp_dim = 4\n",
    "inputs = 'action-reward'\n",
    "dim_output = n_arms\n",
    "estimate_Qvals = True\n",
    "dict_len = 1000\n",
    "kernel = 'cosine' # 'l1' or 'l2'\n",
    "dnd_policy = 'softmax' # 'softmax' or '1NN'\n",
    "unique_keys = True\n",
    "exclude_key = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "''' trainer '''\n",
    "\n",
    "learning_rate = 5e-4 \n",
    "n_epochs = 10\n",
    "beta = 1. # weight for entropy loss\n",
    "gamma = 0.6 # 0.8\n",
    "normalize_return = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(parameterization):\n",
    "    agent = Agent(inp_dim, dim_hidden, dim_output, dict_len, inputs=inputs, ctx_dim=ctx_dim, kernel=kernel, dnd_policy=dnd_policy, unique_keys=unique_keys, q_est=estimate_Qvals)\n",
    "    lr = parameterization.get(\"lr\", 5e-4)\n",
    "    gamma= parameterization.get(\"gamma\", 0.6)\n",
    "    trainer = Trainer(agent, task, seed=seed_val, lr=lr, gamma=gamma)\n",
    "    agent, _, _, _ = trainer.train() \n",
    "    \n",
    "    return evaluate(agent, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-15 11:59:20] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 09-15 11:59:21] ax.service.managed_loop: Started full optimization with 20 steps.\n",
      "[INFO 09-15 11:59:21] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n",
      "Epoch 1 / 100| return = 0.51 | loss: val = 0.43, pol = 0.01, entropy = 2.06 | time = 4.61\n",
      "Score improved (0.000000 --> 0.507998).\n",
      "Epoch 2 / 100| return = 0.61 | loss: val = 0.41, pol = -0.31, entropy = 1.98 | time = 4.46\n",
      "Score improved (0.507998 --> 0.609470).\n",
      "Epoch 3 / 100| return = 0.67 | loss: val = 0.39, pol = -0.44, entropy = 1.97 | time = 4.55\n",
      "Score improved (0.609470 --> 0.673966).\n",
      "Epoch 4 / 100| return = 0.62 | loss: val = 0.42, pol = -0.52, entropy = 1.92 | time = 3.80\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 5 / 100| return = 0.69 | loss: val = 0.39, pol = -0.54, entropy = 1.90 | time = 4.11\n",
      "Score improved (0.673966 --> 0.685620).\n",
      "Epoch 6 / 100| return = 0.66 | loss: val = 0.41, pol = -0.51, entropy = 1.94 | time = 4.48\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 7 / 100| return = 0.70 | loss: val = 0.40, pol = -0.50, entropy = 1.87 | time = 4.40\n",
      "Score improved (0.685620 --> 0.700513).\n",
      "Epoch 8 / 100| return = 0.65 | loss: val = 0.41, pol = -0.59, entropy = 1.89 | time = 4.48\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 9 / 100| return = 0.72 | loss: val = 0.38, pol = -0.62, entropy = 1.86 | time = 4.43\n",
      "Score improved (0.700513 --> 0.722631).\n",
      "Epoch 10 / 100| return = 0.69 | loss: val = 0.38, pol = -0.56, entropy = 1.87 | time = 4.11\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 11 / 100| return = 0.76 | loss: val = 0.38, pol = -0.70, entropy = 1.85 | time = 4.19\n",
      "Score improved (0.722631 --> 0.760972).\n",
      "Epoch 12 / 100| return = 0.74 | loss: val = 0.39, pol = -0.74, entropy = 1.81 | time = 4.32\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 13 / 100| return = 0.79 | loss: val = 0.36, pol = -0.78, entropy = 1.75 | time = 4.35\n",
      "Score improved (0.760972 --> 0.787882).\n",
      "Epoch 14 / 100| return = 0.80 | loss: val = 0.36, pol = -0.78, entropy = 1.76 | time = 4.42\n",
      "Score improved (0.787882 --> 0.799431).\n",
      "Epoch 15 / 100| return = 0.76 | loss: val = 0.37, pol = -0.73, entropy = 1.82 | time = 4.21\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 16 / 100| return = 0.74 | loss: val = 0.38, pol = -0.82, entropy = 1.77 | time = 4.24\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 17 / 100| return = 0.81 | loss: val = 0.35, pol = -0.82, entropy = 1.70 | time = 4.15\n",
      "Score improved (0.799431 --> 0.807640).\n",
      "Epoch 18 / 100| return = 0.81 | loss: val = 0.37, pol = -0.83, entropy = 1.70 | time = 4.17\n",
      "Score improved (0.807640 --> 0.811306).\n",
      "Epoch 19 / 100| return = 0.83 | loss: val = 0.36, pol = -0.72, entropy = 1.71 | time = 4.49\n",
      "Score improved (0.811306 --> 0.830299).\n",
      "Epoch 20 / 100| return = 0.82 | loss: val = 0.36, pol = -0.77, entropy = 1.73 | time = 4.39\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 21 / 100| return = 0.84 | loss: val = 0.34, pol = -0.73, entropy = 1.74 | time = 4.36\n",
      "Score improved (0.830299 --> 0.841261).\n",
      "Epoch 22 / 100| return = 0.80 | loss: val = 0.35, pol = -0.79, entropy = 1.74 | time = 4.62\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 23 / 100| return = 0.80 | loss: val = 0.36, pol = -0.77, entropy = 1.76 | time = 4.23\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 24 / 100| return = 0.80 | loss: val = 0.36, pol = -0.83, entropy = 1.72 | time = 4.45\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 25 / 100| return = 0.83 | loss: val = 0.35, pol = -0.76, entropy = 1.73 | time = 4.16\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 26 / 100| return = 0.81 | loss: val = 0.35, pol = -0.80, entropy = 1.73 | time = 4.29\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 27 / 100| return = 0.82 | loss: val = 0.34, pol = -0.76, entropy = 1.72 | time = 4.39\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 28 / 100| return = 0.86 | loss: val = 0.34, pol = -0.68, entropy = 1.72 | time = 4.30\n",
      "Score improved (0.841261 --> 0.862952).\n",
      "Epoch 29 / 100| return = 0.82 | loss: val = 0.35, pol = -0.67, entropy = 1.76 | time = 4.43\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 30 / 100| return = 0.79 | loss: val = 0.36, pol = -0.79, entropy = 1.77 | time = 4.39\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 31 / 100| return = 0.82 | loss: val = 0.35, pol = -0.77, entropy = 1.75 | time = 4.34\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 32 / 100| return = 0.79 | loss: val = 0.36, pol = -0.84, entropy = 1.76 | time = 4.24\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 33 / 100| return = 0.81 | loss: val = 0.35, pol = -0.68, entropy = 1.75 | time = 4.35\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 34 / 100| return = 0.81 | loss: val = 0.36, pol = -0.80, entropy = 1.75 | time = 4.44\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 35 / 100| return = 0.79 | loss: val = 0.36, pol = -0.87, entropy = 1.73 | time = 4.50\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 36 / 100| return = 0.83 | loss: val = 0.35, pol = -0.68, entropy = 1.76 | time = 4.56\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 37 / 100| return = 0.81 | loss: val = 0.35, pol = -0.80, entropy = 1.75 | time = 4.28\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 38 / 100| return = 0.81 | loss: val = 0.36, pol = -0.78, entropy = 1.75 | time = 4.13\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 39 / 100| return = 0.83 | loss: val = 0.34, pol = -0.75, entropy = 1.73 | time = 4.37\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    39: reducing learning rate of group 0 to 1.2771e-04.\n",
      "Retrieve best model..\n",
      "Epoch 40 / 100| return = 0.81 | loss: val = 0.36, pol = -0.65, entropy = 1.75 | time = 4.47\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 41 / 100| return = 0.79 | loss: val = 0.35, pol = -0.88, entropy = 1.74 | time = 4.36\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 42 / 100| return = 0.83 | loss: val = 0.35, pol = -0.77, entropy = 1.74 | time = 4.41\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 43 / 100| return = 0.82 | loss: val = 0.35, pol = -0.82, entropy = 1.74 | time = 4.36\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 44 / 100| return = 0.81 | loss: val = 0.35, pol = -0.78, entropy = 1.73 | time = 4.31\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 45 / 100| return = 0.83 | loss: val = 0.36, pol = -0.75, entropy = 1.73 | time = 4.42\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 46 / 100| return = 0.82 | loss: val = 0.35, pol = -0.78, entropy = 1.74 | time = 4.41\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 47 / 100| return = 0.85 | loss: val = 0.35, pol = -0.68, entropy = 1.74 | time = 4.49\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 48 / 100| return = 0.82 | loss: val = 0.35, pol = -0.81, entropy = 1.75 | time = 4.23\n",
      "EarlyStopping counter: 20 out of 20\n",
      " Early stopping at epoch 47. Best mean cum. reward : 0.863\n",
      "Retrieve best model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-15 12:02:50] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n",
      "Epoch 1 / 100| return = 0.55 | loss: val = 0.39, pol = -0.19, entropy = 1.94 | time = 4.48\n",
      "Score improved (0.000000 --> 0.548571).\n",
      "Epoch 2 / 100| return = 0.58 | loss: val = 0.42, pol = -0.17, entropy = 2.02 | time = 4.31\n",
      "Score improved (0.548571 --> 0.576510).\n",
      "Epoch 3 / 100| return = 0.60 | loss: val = 0.39, pol = -0.33, entropy = 2.03 | time = 4.22\n",
      "Score improved (0.576510 --> 0.596028).\n",
      "Epoch 4 / 100| return = 0.57 | loss: val = 0.35, pol = -0.24, entropy = 2.01 | time = 4.38\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 5 / 100| return = 0.62 | loss: val = 0.35, pol = -0.09, entropy = 2.00 | time = 4.42\n",
      "Score improved (0.596028 --> 0.624303).\n",
      "Epoch 6 / 100| return = 0.58 | loss: val = 0.32, pol = -0.23, entropy = 2.00 | time = 4.50\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 7 / 100| return = 0.60 | loss: val = 0.33, pol = -0.14, entropy = 2.02 | time = 4.38\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 8 / 100| return = 0.56 | loss: val = 0.35, pol = -0.31, entropy = 2.02 | time = 4.44\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 9 / 100| return = 0.64 | loss: val = 0.28, pol = -0.22, entropy = 1.98 | time = 4.28\n",
      "Score improved (0.624303 --> 0.636337).\n",
      "Epoch 10 / 100| return = 0.63 | loss: val = 0.25, pol = -0.08, entropy = 1.97 | time = 4.45\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 11 / 100| return = 0.67 | loss: val = 0.24, pol = -0.18, entropy = 2.00 | time = 4.53\n",
      "Score improved (0.636337 --> 0.670084).\n",
      "Epoch 12 / 100| return = 0.67 | loss: val = 0.22, pol = -0.25, entropy = 1.95 | time = 4.57\n",
      "Score improved (0.670084 --> 0.671130).\n",
      "Epoch 13 / 100| return = 0.64 | loss: val = 0.24, pol = -0.19, entropy = 2.00 | time = 4.57\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 14 / 100| return = 0.67 | loss: val = 0.17, pol = -0.13, entropy = 2.00 | time = 4.01\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 15 / 100| return = 0.63 | loss: val = 0.19, pol = -0.27, entropy = 1.97 | time = 4.63\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 16 / 100| return = 0.64 | loss: val = 0.20, pol = -0.08, entropy = 1.99 | time = 4.34\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 17 / 100| return = 0.64 | loss: val = 0.18, pol = -0.27, entropy = 1.97 | time = 4.42\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 18 / 100| return = 0.68 | loss: val = 0.16, pol = -0.21, entropy = 1.97 | time = 4.43\n",
      "Score improved (0.671130 --> 0.680244).\n",
      "Epoch 19 / 100| return = 0.68 | loss: val = 0.17, pol = -0.13, entropy = 1.99 | time = 4.49\n",
      "Score improved (0.680244 --> 0.680966).\n",
      "Epoch 20 / 100| return = 0.65 | loss: val = 0.18, pol = -0.22, entropy = 1.99 | time = 4.46\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 21 / 100| return = 0.71 | loss: val = 0.18, pol = -0.15, entropy = 1.99 | time = 4.40\n",
      "Score improved (0.680966 --> 0.706999).\n",
      "Epoch 22 / 100| return = 0.67 | loss: val = 0.20, pol = -0.21, entropy = 1.99 | time = 4.51\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 23 / 100| return = 0.66 | loss: val = 0.18, pol = -0.20, entropy = 1.98 | time = 4.45\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 24 / 100| return = 0.67 | loss: val = 0.19, pol = -0.19, entropy = 1.96 | time = 4.23\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 25 / 100| return = 0.66 | loss: val = 0.19, pol = -0.18, entropy = 2.00 | time = 4.41\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 26 / 100| return = 0.67 | loss: val = 0.20, pol = -0.20, entropy = 1.96 | time = 4.62\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 27 / 100| return = 0.64 | loss: val = 0.15, pol = -0.14, entropy = 1.99 | time = 4.37\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 28 / 100| return = 0.67 | loss: val = 0.18, pol = -0.21, entropy = 1.99 | time = 4.43\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 29 / 100| return = 0.67 | loss: val = 0.21, pol = -0.20, entropy = 1.99 | time = 4.26\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 30 / 100| return = 0.66 | loss: val = 0.19, pol = -0.21, entropy = 1.98 | time = 4.43\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 31 / 100| return = 0.67 | loss: val = 0.18, pol = -0.15, entropy = 1.98 | time = 4.55\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 32 / 100| return = 0.65 | loss: val = 0.15, pol = -0.16, entropy = 1.98 | time = 4.51\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    32: reducing learning rate of group 0 to 6.3782e-03.\n",
      "Retrieve best model..\n",
      "Epoch 33 / 100| return = 0.64 | loss: val = 0.17, pol = -0.22, entropy = 1.99 | time = 4.55\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 34 / 100| return = 0.64 | loss: val = 0.17, pol = -0.24, entropy = 1.98 | time = 4.15\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 35 / 100| return = 0.67 | loss: val = 0.15, pol = -0.21, entropy = 1.97 | time = 4.42\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 36 / 100| return = 0.65 | loss: val = 0.18, pol = -0.24, entropy = 1.98 | time = 4.43\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 37 / 100| return = 0.69 | loss: val = 0.15, pol = -0.19, entropy = 1.97 | time = 4.53\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 38 / 100| return = 0.68 | loss: val = 0.15, pol = -0.16, entropy = 1.99 | time = 5.12\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 39 / 100| return = 0.66 | loss: val = 0.18, pol = -0.31, entropy = 1.98 | time = 4.47\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 40 / 100| return = 0.68 | loss: val = 0.14, pol = -0.16, entropy = 1.98 | time = 4.40\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 41 / 100| return = 0.67 | loss: val = 0.15, pol = -0.23, entropy = 1.98 | time = 4.56\n",
      "EarlyStopping counter: 20 out of 20\n",
      " Early stopping at epoch 40. Best mean cum. reward : 0.707\n",
      "Retrieve best model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-15 12:05:52] ax.service.managed_loop: Running optimization trial 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n",
      "Epoch 1 / 100| return = 0.53 | loss: val = 0.40, pol = -0.17, entropy = 1.98 | time = 4.77\n",
      "Score improved (0.000000 --> 0.532988).\n",
      "Epoch 2 / 100| return = 0.60 | loss: val = 0.33, pol = 0.01, entropy = 2.01 | time = 4.26\n",
      "Score improved (0.532988 --> 0.601550).\n",
      "Epoch 3 / 100| return = 0.62 | loss: val = 0.32, pol = -0.21, entropy = 2.01 | time = 4.18\n",
      "Score improved (0.601550 --> 0.616502).\n",
      "Epoch 4 / 100| return = 0.58 | loss: val = 0.35, pol = -0.26, entropy = 2.02 | time = 4.31\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 5 / 100| return = 0.58 | loss: val = 0.34, pol = -0.11, entropy = 2.01 | time = 4.30\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 6 / 100| return = 0.57 | loss: val = 0.32, pol = -0.05, entropy = 2.03 | time = 4.36\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 7 / 100| return = 0.60 | loss: val = 0.32, pol = -0.42, entropy = 2.01 | time = 4.49\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 8 / 100| return = 0.60 | loss: val = 0.37, pol = -0.19, entropy = 1.97 | time = 5.86\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 9 / 100| return = 0.56 | loss: val = 0.29, pol = 0.01, entropy = 2.01 | time = 4.50\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 10 / 100| return = 0.59 | loss: val = 0.30, pol = -0.08, entropy = 2.01 | time = 4.36\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 11 / 100| return = 0.60 | loss: val = 0.27, pol = -0.14, entropy = 2.01 | time = 4.46\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 12 / 100| return = 0.59 | loss: val = 0.25, pol = -0.07, entropy = 2.00 | time = 4.44\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 13 / 100| return = 0.59 | loss: val = 0.27, pol = -0.22, entropy = 2.02 | time = 4.33\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 14 / 100| return = 0.58 | loss: val = 0.24, pol = -0.17, entropy = 2.01 | time = 4.56\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    14: reducing learning rate of group 0 to 1.6045e-02.\n",
      "Retrieve best model..\n",
      "Epoch 15 / 100| return = 0.60 | loss: val = 0.27, pol = -0.15, entropy = 2.02 | time = 4.46\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 16 / 100| return = 0.55 | loss: val = 0.28, pol = -0.10, entropy = 2.03 | time = 4.57\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 17 / 100| return = 0.56 | loss: val = 0.25, pol = -0.19, entropy = 2.01 | time = 4.50\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 18 / 100| return = 0.60 | loss: val = 0.24, pol = -0.10, entropy = 2.02 | time = 4.27\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 19 / 100| return = 0.61 | loss: val = 0.20, pol = -0.09, entropy = 2.03 | time = 4.41\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 20 / 100| return = 0.61 | loss: val = 0.23, pol = -0.15, entropy = 2.01 | time = 4.26\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 21 / 100| return = 0.64 | loss: val = 0.20, pol = -0.06, entropy = 2.03 | time = 4.34\n",
      "Score improved (0.616502 --> 0.639977).\n",
      "Epoch 22 / 100| return = 0.63 | loss: val = 0.17, pol = -0.13, entropy = 2.01 | time = 4.15\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 23 / 100| return = 0.63 | loss: val = 0.21, pol = -0.21, entropy = 2.02 | time = 4.40\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 24 / 100| return = 0.64 | loss: val = 0.18, pol = -0.09, entropy = 2.00 | time = 4.44\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 25 / 100| return = 0.66 | loss: val = 0.20, pol = -0.21, entropy = 1.99 | time = 4.21\n",
      "Score improved (0.639977 --> 0.658536).\n",
      "Epoch 26 / 100| return = 0.65 | loss: val = 0.19, pol = -0.22, entropy = 1.98 | time = 4.24\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 27 / 100| return = 0.64 | loss: val = 0.15, pol = -0.09, entropy = 1.99 | time = 4.54\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 28 / 100| return = 0.65 | loss: val = 0.19, pol = -0.18, entropy = 2.02 | time = 4.38\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 29 / 100| return = 0.66 | loss: val = 0.20, pol = -0.12, entropy = 2.00 | time = 4.34\n",
      "Score improved (0.658536 --> 0.663128).\n",
      "Epoch 30 / 100| return = 0.65 | loss: val = 0.18, pol = -0.23, entropy = 2.00 | time = 4.22\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 31 / 100| return = 0.68 | loss: val = 0.19, pol = -0.14, entropy = 1.99 | time = 4.18\n",
      "Score improved (0.663128 --> 0.677446).\n",
      "Epoch 32 / 100| return = 0.67 | loss: val = 0.19, pol = -0.13, entropy = 2.00 | time = 4.43\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 33 / 100| return = 0.63 | loss: val = 0.19, pol = -0.16, entropy = 2.00 | time = 4.40\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 34 / 100| return = 0.64 | loss: val = 0.19, pol = -0.26, entropy = 1.98 | time = 4.33\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 35 / 100| return = 0.64 | loss: val = 0.16, pol = -0.19, entropy = 1.97 | time = 4.38\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 36 / 100| return = 0.65 | loss: val = 0.16, pol = -0.18, entropy = 1.98 | time = 4.32\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 37 / 100| return = 0.66 | loss: val = 0.15, pol = -0.19, entropy = 1.99 | time = 4.32\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 38 / 100| return = 0.66 | loss: val = 0.19, pol = -0.19, entropy = 2.01 | time = 4.46\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 39 / 100| return = 0.66 | loss: val = 0.18, pol = -0.11, entropy = 1.99 | time = 4.50\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 40 / 100| return = 0.67 | loss: val = 0.19, pol = -0.23, entropy = 1.99 | time = 4.36\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 41 / 100| return = 0.66 | loss: val = 0.15, pol = -0.20, entropy = 2.00 | time = 4.32\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 42 / 100| return = 0.66 | loss: val = 0.15, pol = -0.18, entropy = 2.01 | time = 5.80\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    42: reducing learning rate of group 0 to 4.8134e-03.\n",
      "Retrieve best model..\n",
      "Epoch 43 / 100| return = 0.67 | loss: val = 0.16, pol = -0.06, entropy = 1.99 | time = 4.80\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 44 / 100| return = 0.64 | loss: val = 0.16, pol = -0.21, entropy = 1.99 | time = 4.47\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 45 / 100| return = 0.67 | loss: val = 0.17, pol = -0.28, entropy = 1.99 | time = 4.55\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 46 / 100| return = 0.67 | loss: val = 0.14, pol = -0.14, entropy = 1.98 | time = 4.26\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 47 / 100| return = 0.68 | loss: val = 0.16, pol = -0.28, entropy = 1.99 | time = 4.46\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 48 / 100| return = 0.69 | loss: val = 0.15, pol = -0.17, entropy = 1.99 | time = 4.90\n",
      "Score improved (0.677446 --> 0.690771).\n",
      "Epoch 49 / 100| return = 0.67 | loss: val = 0.16, pol = -0.07, entropy = 2.00 | time = 4.57\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 50 / 100| return = 0.66 | loss: val = 0.19, pol = -0.22, entropy = 2.00 | time = 4.47\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 51 / 100| return = 0.67 | loss: val = 0.13, pol = -0.09, entropy = 2.01 | time = 4.45\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 52 / 100| return = 0.65 | loss: val = 0.16, pol = -0.26, entropy = 2.01 | time = 4.49\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 53 / 100| return = 0.68 | loss: val = 0.15, pol = -0.16, entropy = 2.00 | time = 4.33\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 54 / 100| return = 0.65 | loss: val = 0.16, pol = -0.23, entropy = 2.00 | time = 4.51\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 55 / 100| return = 0.65 | loss: val = 0.16, pol = -0.14, entropy = 1.98 | time = 4.61\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 56 / 100| return = 0.68 | loss: val = 0.15, pol = -0.20, entropy = 1.99 | time = 4.35\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 57 / 100| return = 0.66 | loss: val = 0.15, pol = -0.17, entropy = 1.98 | time = 4.60\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 58 / 100| return = 0.65 | loss: val = 0.13, pol = -0.16, entropy = 1.99 | time = 4.49\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 59 / 100| return = 0.67 | loss: val = 0.11, pol = -0.12, entropy = 2.00 | time = 4.43\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    59: reducing learning rate of group 0 to 1.4440e-03.\n",
      "Retrieve best model..\n",
      "Epoch 60 / 100| return = 0.69 | loss: val = 0.12, pol = -0.05, entropy = 2.00 | time = 4.62\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 61 / 100| return = 0.63 | loss: val = 0.14, pol = -0.13, entropy = 2.01 | time = 4.51\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 62 / 100| return = 0.64 | loss: val = 0.19, pol = -0.31, entropy = 2.00 | time = 4.42\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 63 / 100| return = 0.65 | loss: val = 0.17, pol = -0.34, entropy = 1.99 | time = 4.39\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 64 / 100| return = 0.67 | loss: val = 0.14, pol = -0.13, entropy = 1.99 | time = 4.20\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 65 / 100| return = 0.65 | loss: val = 0.13, pol = -0.13, entropy = 1.99 | time = 4.52\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 66 / 100| return = 0.66 | loss: val = 0.13, pol = -0.25, entropy = 1.99 | time = 4.49\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 67 / 100| return = 0.64 | loss: val = 0.16, pol = -0.19, entropy = 2.00 | time = 4.46\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 68 / 100| return = 0.67 | loss: val = 0.13, pol = -0.16, entropy = 2.00 | time = 4.17\n",
      "EarlyStopping counter: 20 out of 20\n",
      " Early stopping at epoch 67. Best mean cum. reward : 0.691\n",
      "Retrieve best model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-15 12:10:56] ax.service.managed_loop: Running optimization trial 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n",
      "Epoch 1 / 100| return = 0.61 | loss: val = 1.14, pol = 0.19, entropy = 0.60 | time = 4.18\n",
      "Score improved (0.000000 --> 0.605759).\n",
      "Epoch 2 / 100| return = 0.49 | loss: val = 0.43, pol = -0.11, entropy = 1.77 | time = 4.43\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 3 / 100| return = 0.49 | loss: val = 0.42, pol = -0.08, entropy = 2.00 | time = 4.42\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 4 / 100| return = 0.52 | loss: val = 0.41, pol = -0.08, entropy = 2.01 | time = 4.20\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 5 / 100| return = 0.52 | loss: val = 0.42, pol = -0.10, entropy = 2.04 | time = 4.25\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 6 / 100| return = 0.49 | loss: val = 0.41, pol = -0.02, entropy = 2.05 | time = 4.34\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 7 / 100| return = 0.57 | loss: val = 0.42, pol = -0.05, entropy = 2.04 | time = 4.30\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 8 / 100| return = 0.46 | loss: val = 0.41, pol = -0.03, entropy = 2.04 | time = 4.48\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 9 / 100| return = 0.53 | loss: val = 0.42, pol = -0.04, entropy = 2.02 | time = 4.56\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 10 / 100| return = 0.48 | loss: val = 0.41, pol = 0.02, entropy = 2.04 | time = 4.17\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 11 / 100| return = 0.49 | loss: val = 0.41, pol = -0.11, entropy = 2.03 | time = 4.18\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 12 / 100| return = 0.54 | loss: val = 0.42, pol = -0.03, entropy = 2.04 | time = 4.45\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    12: reducing learning rate of group 0 to 6.2144e-02.\n",
      "Retrieve best model..\n",
      "Epoch 13 / 100| return = 0.53 | loss: val = 0.39, pol = -0.19, entropy = 1.68 | time = 4.55\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 14 / 100| return = 0.48 | loss: val = 0.42, pol = 0.07, entropy = 2.04 | time = 4.54\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 15 / 100| return = 0.51 | loss: val = 0.42, pol = -0.07, entropy = 2.06 | time = 4.40\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 16 / 100| return = 0.47 | loss: val = 0.42, pol = -0.09, entropy = 2.07 | time = 4.79\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 17 / 100| return = 0.48 | loss: val = 0.42, pol = -0.08, entropy = 2.07 | time = 4.47\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 18 / 100| return = 0.52 | loss: val = 0.42, pol = -0.04, entropy = 2.06 | time = 4.58\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 19 / 100| return = 0.56 | loss: val = 0.42, pol = -0.06, entropy = 2.07 | time = 4.87\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 20 / 100| return = 0.53 | loss: val = 0.41, pol = -0.01, entropy = 2.07 | time = 4.54\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 21 / 100| return = 0.55 | loss: val = 0.41, pol = -0.10, entropy = 2.06 | time = 4.11\n",
      "EarlyStopping counter: 20 out of 20\n",
      " Early stopping at epoch 20. Best mean cum. reward : 0.606\n",
      "Retrieve best model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-15 12:12:29] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n",
      "Epoch 1 / 100| return = 0.46 | loss: val = 0.41, pol = 0.39, entropy = 2.07 | time = 4.74\n",
      "Score improved (0.000000 --> 0.463441).\n",
      "Epoch 2 / 100| return = 0.50 | loss: val = 0.41, pol = 0.40, entropy = 2.07 | time = 4.70\n",
      "Score improved (0.463441 --> 0.504792).\n",
      "Epoch 3 / 100| return = 0.50 | loss: val = 0.41, pol = 0.32, entropy = 2.08 | time = 4.48\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 4 / 100| return = 0.51 | loss: val = 0.41, pol = 0.31, entropy = 2.08 | time = 4.43\n",
      "Score improved (0.504792 --> 0.511043).\n",
      "Epoch 5 / 100| return = 0.55 | loss: val = 0.41, pol = 0.34, entropy = 2.07 | time = 4.62\n",
      "Score improved (0.511043 --> 0.552729).\n",
      "Epoch 6 / 100| return = 0.52 | loss: val = 0.41, pol = 0.31, entropy = 2.07 | time = 4.44\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 7 / 100| return = 0.53 | loss: val = 0.41, pol = 0.28, entropy = 2.07 | time = 4.73\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 8 / 100| return = 0.49 | loss: val = 0.40, pol = 0.31, entropy = 2.07 | time = 4.57\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 9 / 100| return = 0.49 | loss: val = 0.41, pol = 0.28, entropy = 2.07 | time = 4.40\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 10 / 100| return = 0.47 | loss: val = 0.40, pol = 0.27, entropy = 2.07 | time = 4.47\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 11 / 100| return = 0.49 | loss: val = 0.40, pol = 0.22, entropy = 2.07 | time = 4.32\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 12 / 100| return = 0.54 | loss: val = 0.40, pol = 0.24, entropy = 2.07 | time = 4.36\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 13 / 100| return = 0.51 | loss: val = 0.40, pol = 0.22, entropy = 2.07 | time = 4.48\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 14 / 100| return = 0.51 | loss: val = 0.40, pol = 0.22, entropy = 2.07 | time = 4.30\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 15 / 100| return = 0.53 | loss: val = 0.40, pol = 0.24, entropy = 2.07 | time = 4.42\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 16 / 100| return = 0.48 | loss: val = 0.40, pol = 0.20, entropy = 2.07 | time = 4.54\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    16: reducing learning rate of group 0 to 6.6299e-06.\n",
      "Retrieve best model..\n",
      "Epoch 17 / 100| return = 0.47 | loss: val = 0.41, pol = 0.33, entropy = 2.07 | time = 4.68\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 18 / 100| return = 0.49 | loss: val = 0.42, pol = 0.33, entropy = 2.07 | time = 4.57\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 19 / 100| return = 0.55 | loss: val = 0.41, pol = 0.37, entropy = 2.07 | time = 4.49\n",
      "Score improved (0.552729 --> 0.553003).\n",
      "Epoch 20 / 100| return = 0.52 | loss: val = 0.40, pol = 0.26, entropy = 2.07 | time = 4.36\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 21 / 100| return = 0.56 | loss: val = 0.40, pol = 0.29, entropy = 2.07 | time = 4.10\n",
      "Score improved (0.553003 --> 0.560702).\n",
      "Epoch 22 / 100| return = 0.50 | loss: val = 0.41, pol = 0.31, entropy = 2.07 | time = 4.33\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 23 / 100| return = 0.53 | loss: val = 0.41, pol = 0.29, entropy = 2.07 | time = 4.24\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 24 / 100| return = 0.51 | loss: val = 0.40, pol = 0.21, entropy = 2.07 | time = 4.34\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 25 / 100| return = 0.50 | loss: val = 0.41, pol = 0.25, entropy = 2.07 | time = 4.28\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 26 / 100| return = 0.51 | loss: val = 0.40, pol = 0.30, entropy = 2.07 | time = 4.56\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 27 / 100| return = 0.50 | loss: val = 0.40, pol = 0.28, entropy = 2.07 | time = 4.42\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 28 / 100| return = 0.53 | loss: val = 0.40, pol = 0.24, entropy = 2.07 | time = 4.66\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 29 / 100| return = 0.52 | loss: val = 0.40, pol = 0.29, entropy = 2.07 | time = 4.86\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 30 / 100| return = 0.52 | loss: val = 0.41, pol = 0.22, entropy = 2.07 | time = 4.26\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 31 / 100| return = 0.54 | loss: val = 0.40, pol = 0.24, entropy = 2.07 | time = 4.33\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 32 / 100| return = 0.51 | loss: val = 0.40, pol = 0.20, entropy = 2.07 | time = 4.31\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    32: reducing learning rate of group 0 to 1.9890e-06.\n",
      "Retrieve best model..\n",
      "Epoch 33 / 100| return = 0.51 | loss: val = 0.40, pol = 0.27, entropy = 2.07 | time = 4.28\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 34 / 100| return = 0.52 | loss: val = 0.41, pol = 0.25, entropy = 2.07 | time = 4.47\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 35 / 100| return = 0.46 | loss: val = 0.41, pol = 0.26, entropy = 2.07 | time = 4.45\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 36 / 100| return = 0.55 | loss: val = 0.40, pol = 0.27, entropy = 2.07 | time = 4.60\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 37 / 100| return = 0.54 | loss: val = 0.40, pol = 0.22, entropy = 2.07 | time = 4.40\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 38 / 100| return = 0.53 | loss: val = 0.40, pol = 0.23, entropy = 2.07 | time = 4.46\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 39 / 100| return = 0.53 | loss: val = 0.40, pol = 0.30, entropy = 2.07 | time = 4.51\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 40 / 100| return = 0.51 | loss: val = 0.41, pol = 0.29, entropy = 2.07 | time = 4.43\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 41 / 100| return = 0.54 | loss: val = 0.40, pol = 0.26, entropy = 2.07 | time = 4.27\n",
      "EarlyStopping counter: 20 out of 20\n",
      " Early stopping at epoch 40. Best mean cum. reward : 0.561\n",
      "Retrieve best model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 09-15 12:15:32] ax.service.managed_loop: Running optimization trial 6...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/src/trainers/trainers.py:86: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/notebooks/src/model/utils.py:110: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (encountering probability entry < 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-60ddaa603c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiArmedBandit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCUES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_arm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_arm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_arm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_arm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m best_parameters, values, experiment, model = optimize(\n\u001b[0m\u001b[1;32m      5\u001b[0m     parameters=[\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"range\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bounds\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log_scale\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/service/managed_loop.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(parameters, evaluation_function, experiment_name, objective_name, minimize, parameter_constraints, outcome_constraints, total_trials, arms_per_trial, random_seed, generation_strategy)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mgeneration_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0mparameterization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparameterization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/service/managed_loop.py\u001b[0m in \u001b[0;36mfull_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Started full optimization with {num_steps} steps.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/service/managed_loop.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid number of arms per trial: {arms_per_trial}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_trial\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/core/base_trial.py\u001b[0m in \u001b[0;36mfetch_data\u001b[0;34m(self, metrics, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mData\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         return self.experiment._fetch_trial_data(\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0mtrial_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/core/simple_experiment.py\u001b[0m in \u001b[0;36m_fetch_trial_data\u001b[0;34m(self, trial_index, metrics, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     ) -> Data:\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcopy_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tracking_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/core/simple_experiment.py\u001b[0m in \u001b[0;36meval_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             evaluations[not_none(trial.arm).name] = self.evaluation_function_outer(\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0mnot_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ax/core/simple_experiment.py\u001b[0m in \u001b[0;36mevaluation_function_outer\u001b[0;34m(self, parameterization, weight)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_evaluation_function_params\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# pyre-fixme[20]: Anonymous call expects argument `$1`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameterization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnum_evaluation_function_params\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameterization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d12068edd407>\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[0;34m(parameterization)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparameterization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/src/trainers/trainers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mturn_on_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mbag_of_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bag_of_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_cues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag_of_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_cum_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_cum_return\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/src/trainers/trainers.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, bag_of_tasks)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_rnd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mAOI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAOI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_indx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/src/trainers/trainers.py\u001b[0m in \u001b[0;36mtrain_one_episode\u001b[0;34m(self, X, Y, AOI, c_indx, rnd, n_trials)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0moutput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0ma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_a_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mf_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrg_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/src/model/QDNDLSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_t, h, c)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mpi_a_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# pick an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0ma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_a_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpick_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi_a_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# reshape data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/src/model/QDNDLSTM.py\u001b[0m in \u001b[0;36mpick_action\u001b[0;34m(self, action_distribution)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[1;32m    119\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0ma_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mlog_prob_a_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob_a_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprobs_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0msample_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (encountering probability entry < 0)"
     ]
    }
   ],
   "source": [
    "'''run bayesian optimization'''\n",
    "\n",
    "task = MultiArmedBandit(cues=CUES, start_arm=start_arm, end_arm=end_arm, ctx_dim=ctx_dim, num_rounds=n_rounds, normalize=normalize_rewards)\n",
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        {\"name\": \"gamma\", \"type\": \"range\", \"bounds\": [0., 1.], \"log_scale\": False}\n",
    "    ],\n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name='accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(agent, task, seed=seed_val, lr=0.04042324285256109, n_trials=n_trials, beta=1., gamma=0.0, normalize_return=True, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score improved (nan --> 0.000000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/src/trainers/trainers.py:86: UserWarning:\n",
      "\n",
      "Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "/notebooks/src/model/utils.py:110: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100| return = 0.61 | loss: val = 0.40, pol = -0.47, entropy = 1.91 | time = 4.44\n",
      "Score improved (0.000000 --> 0.606983).\n",
      "Epoch 2 / 100| return = 0.62 | loss: val = 0.40, pol = -0.45, entropy = 1.92 | time = 4.45\n",
      "Score improved (0.606983 --> 0.624269).\n",
      "Epoch 3 / 100| return = 0.67 | loss: val = 0.38, pol = -0.50, entropy = 1.92 | time = 4.46\n",
      "Score improved (0.624269 --> 0.665312).\n",
      "Epoch 4 / 100| return = 0.64 | loss: val = 0.40, pol = -0.50, entropy = 1.92 | time = 4.29\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 5 / 100| return = 0.65 | loss: val = 0.40, pol = -0.69, entropy = 1.86 | time = 4.63\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 6 / 100| return = 0.66 | loss: val = 0.40, pol = -0.53, entropy = 1.93 | time = 4.29\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 7 / 100| return = 0.66 | loss: val = 0.39, pol = -0.48, entropy = 1.93 | time = 4.48\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 8 / 100| return = 0.64 | loss: val = 0.41, pol = -0.58, entropy = 1.90 | time = 4.13\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 9 / 100| return = 0.67 | loss: val = 0.37, pol = -0.55, entropy = 1.93 | time = 4.47\n",
      "Score improved (0.665312 --> 0.672897).\n",
      "Epoch 10 / 100| return = 0.61 | loss: val = 0.40, pol = -0.57, entropy = 1.90 | time = 4.44\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 11 / 100| return = 0.64 | loss: val = 0.38, pol = -0.50, entropy = 1.90 | time = 4.40\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 12 / 100| return = 0.65 | loss: val = 0.40, pol = -0.55, entropy = 1.88 | time = 4.51\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 13 / 100| return = 0.65 | loss: val = 0.40, pol = -0.51, entropy = 1.90 | time = 4.31\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 14 / 100| return = 0.65 | loss: val = 0.39, pol = -0.53, entropy = 1.89 | time = 4.25\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 15 / 100| return = 0.64 | loss: val = 0.40, pol = -0.62, entropy = 1.90 | time = 4.31\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 16 / 100| return = 0.63 | loss: val = 0.40, pol = -0.57, entropy = 1.88 | time = 4.55\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 17 / 100| return = 0.62 | loss: val = 0.40, pol = -0.62, entropy = 1.86 | time = 4.40\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 18 / 100| return = 0.66 | loss: val = 0.39, pol = -0.60, entropy = 1.85 | time = 4.17\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 19 / 100| return = 0.65 | loss: val = 0.39, pol = -0.43, entropy = 1.93 | time = 4.18\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 20 / 100| return = 0.63 | loss: val = 0.40, pol = -0.54, entropy = 1.91 | time = 4.13\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch    20: reducing learning rate of group 0 to 1.2127e-02.\n",
      "Retrieve best model..\n",
      "Epoch 21 / 100| return = 0.62 | loss: val = 0.41, pol = -0.52, entropy = 1.93 | time = 4.44\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 22 / 100| return = 0.61 | loss: val = 0.40, pol = -0.48, entropy = 1.93 | time = 4.36\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 23 / 100| return = 0.62 | loss: val = 0.41, pol = -0.56, entropy = 1.92 | time = 4.40\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 24 / 100| return = 0.66 | loss: val = 0.39, pol = -0.43, entropy = 1.91 | time = 4.13\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 25 / 100| return = 0.62 | loss: val = 0.41, pol = -0.53, entropy = 1.93 | time = 4.27\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 26 / 100| return = 0.63 | loss: val = 0.40, pol = -0.59, entropy = 1.90 | time = 4.43\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 27 / 100| return = 0.67 | loss: val = 0.36, pol = -0.50, entropy = 1.91 | time = 4.13\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 28 / 100| return = 0.67 | loss: val = 0.37, pol = -0.56, entropy = 1.92 | time = 4.21\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 29 / 100| return = 0.67 | loss: val = 0.39, pol = -0.54, entropy = 1.91 | time = 4.18\n",
      "EarlyStopping counter: 20 out of 20\n",
      " Early stopping at epoch 28. Best mean cum. reward : 0.673\n",
      "Retrieve best model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(QDNDLSTM(\n",
       "   (i2h): Linear(in_features=4, out_features=320, bias=True)\n",
       "   (h2h): Linear(in_features=64, out_features=320, bias=True)\n",
       "   (a2c): A2C(\n",
       "     (ih): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (actor): Linear(in_features=64, out_features=8, bias=True)\n",
       "     (critic): Linear(in_features=64, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " array([-793.96814728, -788.40180206, -815.083395  , -804.48659706,\n",
       "        -858.81056976, -825.11432838, -807.81925774, -829.30327988,\n",
       "        -842.63593102, -827.10493565, -806.55787659, -811.88845062,\n",
       "        -801.55737495, -815.06477356, -844.14279175, -820.81296349,\n",
       "        -830.50608444, -824.38023949, -784.02799416, -817.92995834,\n",
       "        -817.5187149 , -802.81866646, -828.91145897, -781.86576653,\n",
       "        -818.45567513, -835.49422073, -820.42216301, -842.72343063,\n",
       "        -825.63899422]),\n",
       " array([0.60698304, 0.62426891, 0.6653115 , 0.64456321, 0.65419962,\n",
       "        0.65512973, 0.65999876, 0.63995957, 0.67289702, 0.61404091,\n",
       "        0.63885402, 0.65071675, 0.64573309, 0.64739554, 0.6429281 ,\n",
       "        0.62887385, 0.62447156, 0.65720454, 0.6542824 , 0.63222674,\n",
       "        0.61518493, 0.60927684, 0.62190289, 0.65707418, 0.62047531,\n",
       "        0.62777416, 0.66823341, 0.67045595, 0.67142114]),\n",
       " [0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.04042324285256109,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326,\n",
       "  0.012126972855768326])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.04042324285256109, 'gamma': 0.0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.9999999506759155},\n",
       " {'accuracy': {'accuracy': 2.6315786918006343e-09}})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, covariances = values\n",
    "means, covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8880ba2fd0>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optimization runs, so we wrap out best objectives array in another array.\n",
    "best_objectives = np.array([[trial.objective_mean*100 for trial in experiment.trials.values()]])\n",
    "plt.plot(best_objectives[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
